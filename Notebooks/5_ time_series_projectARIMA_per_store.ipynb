{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O0ylMFj3c-cO"
   },
   "source": [
    "#Corporaci√≥n Favorita Grocery Sales Forecasting\n",
    "The objective is to predict future sales of items in Favorita grocery stores across different regions of Ecuador. So that Reliable predictions can be helpful to optimize inventory management, prevent stockouts, and improve promotion strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U7SsUxpbgmWg"
   },
   "source": [
    "#1- Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IzNKECuHahDd"
   },
   "outputs": [],
   "source": [
    "!pip install -q pmdarima numpy==1.26.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0aGlnszJrJfS"
   },
   "outputs": [],
   "source": [
    "!pip install -q pmdarima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dWOv7gmnYNZM"
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima.model  import ARIMA\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from pmdarima import auto_arima\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(15, 5)})\n",
    "sns.set(font_scale=2)\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "import warnings\n",
    "# Ignore FutureWarning from the 'sklearn.utils.deprecation' module\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module='sklearn.utils.deprecation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1023,
     "status": "ok",
     "timestamp": 1749828722482,
     "user": {
      "displayName": "nuzhat amna",
      "userId": "14208939946541820310"
     },
     "user_tz": -120
    },
    "id": "Y2Gfr03JzCGs",
    "outputId": "f6bd4260-c33b-4873-c7b1-7a1cbfeb8173"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "#mount google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y2eLirWIr-dO"
   },
   "source": [
    "# 2- Data Retreival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bR3atFl-LCBF"
   },
   "outputs": [],
   "source": [
    "# Select data before April'14\n",
    "max_date = '2014-04-01'\n",
    "\n",
    "# Initialize an empty list to hold filtered chunks\n",
    "filtered_chunks = []\n",
    "\n",
    "# Define the chunk size (number of rows per chunk)\n",
    "chunk_size = 10 ** 6\n",
    "\n",
    "# Read the CSV file in chunks\n",
    "file_path = '/Users/D065623/Documents/Amna/Time_series_project/Data/'\n",
    "for chunk in pd.read_csv(file_path + 'train_Guayas_featureEngg.csv', chunksize=chunk_size):\n",
    "\n",
    "    chunk_filtered = chunk[(chunk['date']<max_date)]\n",
    "    # Append the filtered chunk to the list\n",
    "    filtered_chunks.append(chunk_filtered)\n",
    "\n",
    "    del chunk\n",
    "\n",
    "# Concatenate all filtered chunks into a single DataFrame\n",
    "df_filtered = pd.concat(filtered_chunks, ignore_index=True)\n",
    "\n",
    "# Clean up to free memory\n",
    "del filtered_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "executionInfo": {
     "elapsed": 3419,
     "status": "ok",
     "timestamp": 1749828904728,
     "user": {
      "displayName": "nuzhat amna",
      "userId": "14208939946541820310"
     },
     "user_tz": -120
    },
    "id": "DfBw9L_oaEnw",
    "outputId": "3c3a6200-bf0b-4ee5-be65-189d37450b70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9437752, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>unit_sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>unit_sales_7d_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>105574</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>18790.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.86605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>105574</td>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>59692.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2.86605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>105574</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>99664.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.86605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>105574</td>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>140805.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2.86605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>105574</td>\n",
       "      <td>2013-01-06</td>\n",
       "      <td>182800.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2.86605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   store_nbr  item_nbr        date        id  unit_sales  onpromotion  year  \\\n",
       "0         24    105574  2013-01-02   18790.0        12.0        False  2013   \n",
       "1         24    105574  2013-01-03   59692.0         1.0        False  2013   \n",
       "2         24    105574  2013-01-04   99664.0         3.0        False  2013   \n",
       "3         24    105574  2013-01-05  140805.0         4.0        False  2013   \n",
       "4         24    105574  2013-01-06  182800.0         7.0        False  2013   \n",
       "\n",
       "   month  day  day_of_week  unit_sales_7d_avg  \n",
       "0      1    2            2            2.86605  \n",
       "1      1    3            3            2.86605  \n",
       "2      1    4            4            2.86605  \n",
       "3      1    5            5            2.86605  \n",
       "4      1    6            6            2.86605  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_filtered.copy()\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6lG3IyjxuxCB"
   },
   "source": [
    "# 3. Classical Model for Time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5KckNNTbCaO"
   },
   "source": [
    "## 3.1- SARIMA + autoarima\n",
    "SARIMA stands for Seasonal Autoregressive Integrated Moving Average. It is an extension of the ARIMA model that explicitly handles time series with a seasonal component. A SARIMA model is typically denoted as SARIMA(p, d, q)(P, D, Q, m).\n",
    "- p: Order of the non-seasonal Autoregressive (AR) part.\n",
    "- d: Order of non-seasonal differencing (Integrated part).\n",
    "- q: Order of the non-seasonal Moving Average (MA) part.\n",
    "\n",
    "In addition to these, SARIMA includes seasonal components denoted as (P, D, Q, m):\n",
    "\n",
    "- P: Order of the seasonal Autoregressive (AR) part.\n",
    "- D: Order of seasonal differencing (Seasonal Integrated part).\n",
    "- Q: Order of the seasonal Moving Average (MA) part.\n",
    "- m: The number of time steps for a single seasonal period (e.g.,for given case 7 for daily data with weekly seasonality)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lITj7WM5LCBG"
   },
   "outputs": [],
   "source": [
    "def model_evaluation(model, test_size = 90, exog=None):\n",
    "    '''\n",
    "    This function evaluates the model on a given test size\n",
    "    '''\n",
    "    train_predictions = model.predict()\n",
    "    if exog is not None:\n",
    "        forecast = model.get_forecast(test_size, exog = df[-test_size:][exog])\n",
    "        test_predictions = forecast.predicted_mean\n",
    "\n",
    "    else:\n",
    "        try:\n",
    "            test_predictions = model.forecast(test_size)\n",
    "\n",
    "        except:\n",
    "            test_predictions = model.predict(test_size)\n",
    "\n",
    "    print(len(test_predictions))\n",
    "    mae = mean_absolute_error(df[-test_size:]['unit_sales'], test_predictions)\n",
    "    r2 = r2_score(df[-test_size:]['unit_sales'], test_predictions)\n",
    "    print(f'R2 score {np.round(r2,2)}\\nMean absolute error {np.round(mae,2)}')\n",
    "\n",
    "\n",
    "    #plot\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(train_predictions, label = 'Train predictions')\n",
    "    ax.plot(df['unit_sales'], label = 'Input data')\n",
    "    ax.plot(test_predictions, label = 'Test predictions')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9fuPZ_BYLCBG"
   },
   "source": [
    "## 3.2: Model Training per Store Per Item, and forecast their sale\n",
    "\n",
    "For each Store in Guayas region, top 10 sold items are selected and used to train an Auto-Arima model per item. As there are 10 Stores and 10 item each, hence 100 auto-arima models are trained.\n",
    "\n",
    "The trained models forecasts per store per item are saved in a dictionary and later exported as Json. This Json file will be used with app.py to show results in the streamlit app.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cDXX8jZ8LCBG",
    "outputId": "3f1c40cb-cedc-4d52-c9da-17a38d5f1ff9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24 26 27 28 30 32 34 35 51 36]\n"
     ]
    }
   ],
   "source": [
    "unique_stores = df['store_nbr'].unique()\n",
    "\n",
    "#drop store nbr 29 because of no sales from unique_stores\n",
    "unique_stores = unique_stores[unique_stores != 29]\n",
    "print(unique_stores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X3IG9vRcLCBG"
   },
   "outputs": [],
   "source": [
    "# Initialize a dictionary to hold forecasts for each store\n",
    "stores_forecasts = {}\n",
    "\n",
    "# For each store, groupby item_nbr and aggregate sales to find the top_10 sales items. Each store will have its own top_10 items\n",
    "for store in unique_stores:\n",
    "    store_k = str(store)\n",
    "    stores_forecasts[store_k] = {}\n",
    "\n",
    "    store_data = df[df['store_nbr'] == store]\n",
    "    top_items = store_data.groupby('item_nbr')['unit_sales'].sum().nlargest(10).index.tolist()\n",
    "    stores_forecasts[store_k]['top_items'] = top_items\n",
    "\n",
    "    # make store top items as key a new dictionatry in stores_forecasts[store]\n",
    "    for item in top_items:\n",
    "        item_k = str(item)\n",
    "        stores_forecasts[store_k][item_k] = {}\n",
    "\n",
    "#print(stores_forecasts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P7nzTrC1LCBH",
    "outputId": "a90fb622-6067-4aaa-fad7-9dd9e42308d6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Store 24, Item 257847 Bias: 35.11, MAD: 87.8, rMAD: 0.42, r2: -0.3, mae: 87.8\n",
      "2. Store 24, Item 1047679 Bias: -12.96, MAD: 55.37, rMAD: 0.47, r2: -0.61, mae: 55.37\n",
      "3. Store 24, Item 819932 Bias: -16.74, MAD: 48.63, rMAD: 0.55, r2: -0.55, mae: 48.63\n",
      "4. Store 24, Item 315176 Bias: 29.06, MAD: 37.33, rMAD: 0.37, r2: -0.12, mae: 37.33\n",
      "5. Store 24, Item 305080 Bias: -9.84, MAD: 26.26, rMAD: 0.35, r2: -0.54, mae: 26.26\n",
      "6. Store 24, Item 839362 Bias: -11.1, MAD: 25.99, rMAD: 1.27, r2: 0.29, mae: 25.99\n",
      "7. Store 24, Item 559870 Bias: -10.69, MAD: 16.76, rMAD: 0.3, r2: -0.39, mae: 16.76\n",
      "8. Store 24, Item 215352 Bias: 9.55, MAD: 22.59, rMAD: 0.36, r2: -0.1, mae: 22.59\n",
      "9. Store 24, Item 364606 Bias: -15.37, MAD: 22.5, rMAD: 0.49, r2: -0.78, mae: 22.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñà         | 1/10 [02:08<19:15, 128.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10. Store 24, Item 1037857 Bias: 11.99, MAD: 35.1, rMAD: 0.62, r2: -0.25, mae: 35.1\n",
      "--------------------------------------------------\n",
      "11. Store 26, Item 839362 Bias: -5.94, MAD: 31.9, rMAD: 1.19, r2: -0.71, mae: 31.9\n",
      "12. Store 26, Item 364606 Bias: -21.67, MAD: 25.41, rMAD: 1.17, r2: -6.08, mae: 25.41\n",
      "13. Store 26, Item 265559 Bias: -24.56, MAD: 32.84, rMAD: 0.96, r2: -3.45, mae: 32.84\n",
      "14. Store 26, Item 807493 Bias: -6.81, MAD: 16.55, rMAD: 0.66, r2: -0.2, mae: 16.55\n",
      "15. Store 26, Item 305080 Bias: -27.8, MAD: 31.21, rMAD: 1.31, r2: -7.9, mae: 31.21\n",
      "16. Store 26, Item 841842 Bias: -6.83, MAD: 16.17, rMAD: 0.55, r2: -0.2, mae: 16.17\n",
      "17. Store 26, Item 220435 Bias: -10.11, MAD: 12.54, rMAD: 0.56, r2: -1.02, mae: 12.54\n",
      "18. Store 26, Item 115611 Bias: -15.32, MAD: 15.75, rMAD: 0.65, r2: -3.07, mae: 15.75\n",
      "19. Store 26, Item 559870 Bias: -17.68, MAD: 20.87, rMAD: 0.72, r2: -1.79, mae: 20.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñà        | 2/10 [09:59<44:00, 330.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20. Store 26, Item 215352 Bias: -2.57, MAD: 7.32, rMAD: 0.47, r2: 0.05, mae: 7.32\n",
      "--------------------------------------------------\n",
      "21. Store 27, Item 839362 Bias: -19.82, MAD: 53.77, rMAD: 1.12, r2: 0.18, mae: 53.77\n",
      "22. Store 27, Item 257847 Bias: -2.92, MAD: 37.03, rMAD: 0.52, r2: 0.27, mae: 37.03\n",
      "23. Store 27, Item 315176 Bias: 61.08, MAD: 63.63, rMAD: 0.64, r2: -0.3, mae: 63.63\n",
      "24. Store 27, Item 559870 Bias: -2.14, MAD: 14.39, rMAD: 0.25, r2: 0.27, mae: 14.39\n",
      "25. Store 27, Item 305080 Bias: 2.04, MAD: 9.67, rMAD: 0.23, r2: 0.28, mae: 9.67\n",
      "26. Store 27, Item 819932 Bias: -5.71, MAD: 15.66, rMAD: 0.38, r2: 0.39, mae: 15.66\n",
      "27. Store 27, Item 215352 Bias: 26.04, MAD: 28.47, rMAD: 0.52, r2: -0.28, mae: 28.47\n",
      "28. Store 27, Item 265559 Bias: 7.55, MAD: 13.17, rMAD: 0.31, r2: 0.09, mae: 13.17\n",
      "29. Store 27, Item 364606 Bias: -12.71, MAD: 15.34, rMAD: 0.53, r2: -1.36, mae: 15.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|‚ñà‚ñà‚ñà       | 3/10 [13:40<32:39, 279.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30. Store 27, Item 807493 Bias: -0.39, MAD: 11.92, rMAD: 0.36, r2: 0.4, mae: 11.92\n",
      "--------------------------------------------------\n",
      "31. Store 28, Item 807493 Bias: 0.67, MAD: 25.93, rMAD: 0.34, r2: 0.17, mae: 25.93\n",
      "32. Store 28, Item 1158720 Bias: 60.54, MAD: 127.44, rMAD: 0.8, r2: -0.21, mae: 127.44\n",
      "33. Store 28, Item 559870 Bias: -4.46, MAD: 24.82, rMAD: 0.36, r2: 0.09, mae: 24.82\n",
      "34. Store 28, Item 839362 Bias: 14.59, MAD: 23.44, rMAD: 0.57, r2: 0.37, mae: 23.44\n",
      "35. Store 28, Item 1143685 Bias: 17.05, MAD: 33.74, rMAD: 0.4, r2: -0.13, mae: 33.74\n",
      "36. Store 28, Item 315176 Bias: 26.51, MAD: 29.22, rMAD: 0.49, r2: 0.31, mae: 29.22\n",
      "37. Store 28, Item 638977 Bias: -6.28, MAD: 11.34, rMAD: 0.22, r2: 0.57, mae: 11.34\n",
      "38. Store 28, Item 265559 Bias: -0.96, MAD: 14.18, rMAD: 0.34, r2: 0.43, mae: 14.18\n",
      "39. Store 28, Item 364606 Bias: -13.86, MAD: 14.66, rMAD: 0.4, r2: -0.14, mae: 14.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 4/10 [20:13<32:28, 324.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40. Store 28, Item 257847 Bias: -4.22, MAD: 37.92, rMAD: 0.89, r2: -0.39, mae: 37.92\n",
      "--------------------------------------------------\n",
      "41. Store 30, Item 257847 Bias: -7.74, MAD: 40.34, rMAD: 1.1, r2: -0.39, mae: 40.34\n",
      "42. Store 30, Item 215352 Bias: 10.07, MAD: 11.85, rMAD: 0.49, r2: -0.65, mae: 11.85\n",
      "43. Store 30, Item 155500 Bias: -4.86, MAD: 8.43, rMAD: 0.44, r2: -0.25, mae: 8.43\n",
      "44. Store 30, Item 364606 Bias: -0.1, MAD: 6.52, rMAD: 0.34, r2: -0.14, mae: 6.52\n",
      "45. Store 30, Item 1047743 Bias: 8.34, MAD: 15.56, rMAD: 0.64, r2: 0.12, mae: 15.56\n",
      "46. Store 30, Item 265559 Bias: -7.6, MAD: 9.29, rMAD: 0.65, r2: -1.69, mae: 9.29\n",
      "47. Store 30, Item 638977 Bias: -8.34, MAD: 9.95, rMAD: 0.66, r2: -4.06, mae: 9.95\n",
      "48. Store 30, Item 1158720 Bias: -15.41, MAD: 16.97, rMAD: 1.0, r2: -2.3, mae: 16.97\n",
      "49. Store 30, Item 807493 Bias: 4.52, MAD: 14.01, rMAD: 0.66, r2: -0.07, mae: 14.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 5/10 [25:27<26:43, 320.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50. Store 30, Item 1146786 Bias: -3.61, MAD: 7.56, rMAD: 0.45, r2: 0.14, mae: 7.56\n",
      "--------------------------------------------------\n",
      "51. Store 32, Item 839362 Bias: 9.91, MAD: 12.58, rMAD: 0.54, r2: -0.43, mae: 12.58\n",
      "52. Store 32, Item 265559 Bias: 2.29, MAD: 6.53, rMAD: 0.34, r2: 0.06, mae: 6.53\n",
      "53. Store 32, Item 364606 Bias: -3.53, MAD: 4.47, rMAD: 0.47, r2: -0.39, mae: 4.47\n",
      "54. Store 32, Item 749421 Bias: 4.04, MAD: 6.73, rMAD: 0.43, r2: 0.32, mae: 6.73\n",
      "55. Store 32, Item 1012473 Bias: -0.23, MAD: 8.06, rMAD: 0.41, r2: 0.16, mae: 8.06\n",
      "56. Store 32, Item 220435 Bias: -6.05, MAD: 8.99, rMAD: 0.71, r2: -4.65, mae: 8.99\n",
      "57. Store 32, Item 320682 Bias: -6.88, MAD: 9.33, rMAD: 0.9, r2: -3.17, mae: 9.33\n",
      "58. Store 32, Item 215352 Bias: 2.2, MAD: 6.1, rMAD: 0.36, r2: 0.16, mae: 6.1\n",
      "59. Store 32, Item 165594 Bias: -4.51, MAD: 4.81, rMAD: 0.5, r2: -1.07, mae: 4.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 6/10 [30:48<21:24, 321.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60. Store 32, Item 1146786 Bias: 0.84, MAD: 6.03, rMAD: 0.46, r2: -0.12, mae: 6.03\n",
      "--------------------------------------------------\n",
      "61. Store 34, Item 807493 Bias: -21.15, MAD: 60.64, rMAD: 0.52, r2: 0.2, mae: 60.64\n",
      "62. Store 34, Item 215352 Bias: 19.65, MAD: 41.0, rMAD: 0.37, r2: 0.02, mae: 41.0\n",
      "63. Store 34, Item 364606 Bias: -88.46, MAD: 88.46, rMAD: 2.05, r2: -46.24, mae: 88.46\n",
      "64. Store 34, Item 938566 Bias: -63.92, MAD: 64.76, rMAD: 1.26, r2: -4.0, mae: 64.76\n",
      "65. Store 34, Item 839362 Bias: -2.9, MAD: 13.26, rMAD: 1.15, r2: -0.86, mae: 13.26\n",
      "66. Store 34, Item 265254 Bias: -9.01, MAD: 12.94, rMAD: 0.23, r2: 0.28, mae: 12.94\n",
      "67. Store 34, Item 819932 Bias: -20.62, MAD: 44.41, rMAD: 0.81, r2: -1.5, mae: 44.41\n",
      "68. Store 34, Item 115894 Bias: 6.71, MAD: 26.59, rMAD: 0.37, r2: 0.01, mae: 26.59\n",
      "69. Store 34, Item 1146786 Bias: -11.41, MAD: 21.43, rMAD: 0.42, r2: -0.11, mae: 21.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 7/10 [35:17<15:11, 303.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70. Store 34, Item 1158720 Bias: -16.39, MAD: 31.41, rMAD: 0.46, r2: -0.04, mae: 31.41\n",
      "--------------------------------------------------\n",
      "71. Store 35, Item 692531 Bias: -9.07, MAD: 24.88, rMAD: 0.67, r2: -0.07, mae: 24.88\n",
      "72. Store 35, Item 1161572 Bias: 6.17, MAD: 26.61, rMAD: 0.49, r2: -0.04, mae: 26.61\n",
      "73. Store 35, Item 874593 Bias: 21.7, MAD: 37.96, rMAD: 0.61, r2: -0.09, mae: 37.96\n",
      "74. Store 35, Item 215352 Bias: 23.45, MAD: 31.81, rMAD: 0.66, r2: -0.6, mae: 31.81\n",
      "75. Store 35, Item 115894 Bias: 10.7, MAD: 28.35, rMAD: 0.68, r2: -0.19, mae: 28.35\n",
      "76. Store 35, Item 1158720 Bias: 28.74, MAD: 51.03, rMAD: 0.81, r2: -0.04, mae: 51.03\n",
      "77. Store 35, Item 1047743 Bias: 15.8, MAD: 55.92, rMAD: 1.17, r2: -0.03, mae: 55.92\n",
      "78. Store 35, Item 770449 Bias: 2.42, MAD: 25.96, rMAD: 0.59, r2: 0.12, mae: 25.96\n",
      "79. Store 35, Item 807493 Bias: 11.04, MAD: 21.83, rMAD: 0.58, r2: -0.25, mae: 21.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 8/10 [38:33<08:59, 269.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80. Store 35, Item 1146786 Bias: -7.64, MAD: 14.73, rMAD: 0.65, r2: -0.03, mae: 14.73\n",
      "--------------------------------------------------\n",
      "81. Store 51, Item 257847 Bias: -12.1, MAD: 72.88, rMAD: 0.31, r2: -0.11, mae: 72.88\n",
      "82. Store 51, Item 315176 Bias: 30.48, MAD: 53.68, rMAD: 0.31, r2: 0.3, mae: 53.68\n",
      "83. Store 51, Item 418235 Bias: -24.41, MAD: 53.8, rMAD: 0.61, r2: -1.2, mae: 53.8\n",
      "84. Store 51, Item 364738 Bias: 52.11, MAD: 64.21, rMAD: 0.52, r2: 0.03, mae: 64.21\n",
      "85. Store 51, Item 1047679 Bias: 18.06, MAD: 43.03, rMAD: 0.35, r2: -0.07, mae: 43.03\n",
      "86. Store 51, Item 819932 Bias: 2.61, MAD: 42.71, rMAD: 0.5, r2: 0.16, mae: 42.71\n",
      "87. Store 51, Item 305080 Bias: -61.76, MAD: 68.27, rMAD: 0.81, r2: -15.27, mae: 68.27\n",
      "88. Store 51, Item 1074327 Bias: 13.55, MAD: 28.45, rMAD: 0.29, r2: 0.36, mae: 28.45\n",
      "89. Store 51, Item 364606 Bias: -26.61, MAD: 28.18, rMAD: 0.44, r2: -2.57, mae: 28.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 9/10 [41:25<03:59, 239.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90. Store 51, Item 559870 Bias: 8.79, MAD: 21.4, rMAD: 0.25, r2: 0.09, mae: 21.4\n",
      "--------------------------------------------------\n",
      "91. Store 36, Item 807493 Bias: 2.84, MAD: 15.97, rMAD: 0.22, r2: 0.43, mae: 15.97\n",
      "92. Store 36, Item 215352 Bias: -8.68, MAD: 19.43, rMAD: 0.33, r2: 0.27, mae: 19.43\n",
      "93. Store 36, Item 1143685 Bias: 10.68, MAD: 26.73, rMAD: 0.38, r2: 0.07, mae: 26.73\n",
      "94. Store 36, Item 115894 Bias: 2.57, MAD: 16.43, rMAD: 0.33, r2: -0.19, mae: 16.43\n",
      "95. Store 36, Item 1158720 Bias: 16.92, MAD: 20.47, rMAD: 0.38, r2: -0.5, mae: 20.47\n",
      "96. Store 36, Item 839362 Bias: 7.42, MAD: 13.23, rMAD: 0.61, r2: 0.02, mae: 13.23\n",
      "97. Store 36, Item 1161572 Bias: 6.54, MAD: 13.83, rMAD: 0.33, r2: -0.19, mae: 13.83\n",
      "98. Store 36, Item 1146786 Bias: 2.3, MAD: 9.31, rMAD: 0.37, r2: -0.3, mae: 9.31\n",
      "99. Store 36, Item 364606 Bias: -16.94, MAD: 16.94, rMAD: 0.82, r2: -3.31, mae: 16.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [45:20<00:00, 272.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100. Store 36, Item 155500 Bias: -11.01, MAD: 16.21, rMAD: 0.54, r2: -1.77, mae: 16.21\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# for each store in unique_stores, prepate the data to be used in Auto ARIMA model,\n",
    "# and then enrich the stores_forecasts dictionary with the forecasts for each store and item\n",
    "\n",
    "plotting = False\n",
    "count = 0\n",
    "\n",
    "# Number of periods to forecast, for example, 90 for 3 months forecast\n",
    "n_periods = 15\n",
    "\n",
    "for store in tqdm(unique_stores):\n",
    "    store_k = str(store)\n",
    "    store_data = df[df['store_nbr'] == store]\n",
    "\n",
    "    for item in stores_forecasts[store_k]['top_items']:\n",
    "        count += 1\n",
    "        item_k = str(item)\n",
    "\n",
    "        # Filter data for the specific item\n",
    "        item_data = store_data[store_data['item_nbr'] == item]\n",
    "\n",
    "        item_data_sales = item_data.groupby('date').sum()['unit_sales'].reset_index()\n",
    "        item_data_sales.set_index('date', inplace=True)\n",
    "        item_data_sales.index = pd.DatetimeIndex(item_data_sales.index.values, freq='D')\n",
    "\n",
    "        # Ensure the data is sorted by date\n",
    "        item_data_sales = item_data_sales.sort_index()\n",
    "\n",
    "        # split into train and test sets as per split date\n",
    "        train_data, test_data = item_data_sales.loc[:'2013-12-31'], item_data_sales.loc['2014-01-01':]\n",
    "        test_data = test_data.head(n_periods)  # Limit test data to n_periods\n",
    "\n",
    "        if plotting:\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.plot(train_data['unit_sales'], label='Train Data')\n",
    "            ax.plot(test_data['unit_sales'], label='Test Data')\n",
    "            plt.title(f'Store {store_k}, Item {item_k} Sales Data')\n",
    "            plt.xlabel('Date')\n",
    "            plt.ylabel('Unit Sales')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "        # Fit the Auto ARIMA model\n",
    "        model = auto_arima(train_data,\n",
    "                         start_p=1, start_q=1,\n",
    "                         test='adf',\n",
    "                         max_p=25, max_q=25,\n",
    "                         m=7, #7 is the frequncy of the cycle\n",
    "                         start_P=0,\n",
    "                         seasonal=True, #set to seasonal\n",
    "                         d=0, #order of the non-seasonal differencing\n",
    "                         D=1, #order of the seasonal differencing\n",
    "                         trace=False,\n",
    "                         error_action='ignore',\n",
    "                         suppress_warnings=True,\n",
    "                         stepwise=True)\n",
    "\n",
    "\n",
    "        # Forecast for the next 90 days\n",
    "        forecast = model.predict(n_periods=n_periods)\n",
    "        forecasted_data = pd.DataFrame({'date': pd.date_range(start='2014-01-01', periods=n_periods, freq='D'),\n",
    "                                 'unit_sales': test_data['unit_sales'],\n",
    "                                 'forcasted_unit_sales': forecast})\n",
    "        forecasted_data.set_index('date', inplace=True)\n",
    "\n",
    "\n",
    "        # save the train and test data to the stores_forecasts dictionary (optional)\n",
    "        stores_forecasts[store_k][item_k]['train_data'] = train_data['unit_sales'].round(2).tolist()\n",
    "        stores_forecasts[store_k][item_k]['test_data'] = test_data['unit_sales'].round(2).tolist()\n",
    "\n",
    "        # Store the actual and forecasted data in the dictionary, with upto 2 decimal points\n",
    "        stores_forecasts[store_k][item_k]['forecast'] = forecasted_data['forcasted_unit_sales'].round(2).tolist()\n",
    "\n",
    "        #stores_forecasts[store_k][item_k]['forecast'] = forecasted_data['forcasted_unit_sales'].tolist()\n",
    "\n",
    "        # Optionally, you can also store the confidence intervals of forecasted_data if available\n",
    "        # Get confidence intervals if available\n",
    "\n",
    "        try:\n",
    "\n",
    "            forecast = model.get_forecast(steps=n_periods)\n",
    "            confidence_intervals = forecast.conf_int()\n",
    "\n",
    "        except AttributeError:\n",
    "            # If the model does not support confidence intervals, set to None\n",
    "            confidence_intervals = None\n",
    "        except Exception as e:\n",
    "            confidence_intervals = None\n",
    "\n",
    "        # Store confidence intervals in the dictionary\n",
    "        stores_forecasts[store_k][item_k]['confidence_intervals'] = confidence_intervals\n",
    "\n",
    "        if plotting:\n",
    "            # Plot the forecasted data\n",
    "            plt.figure(figsize=(15, 5))\n",
    "            plt.plot(forecasted_data.index, forecasted_data['unit_sales'], label='Actual')\n",
    "            plt.plot(forecasted_data.index, forecasted_data['forcasted_unit_sales'], label='Forecast')\n",
    "\n",
    "            # Plot confidence intervals if available\n",
    "            if confidence_intervals is not None:\n",
    "                # Convert confidence intervals to DataFrame for plotting\n",
    "                ci = pd.DataFrame(confidence_intervals, index=forecasted_data.index)\n",
    "                # Plot the confidence intervals\n",
    "                plt.fill_between(ci.index, ci.iloc[:, 0], ci.iloc[:, 1], color='gray', alpha=0.2, label='Confidence Interval')\n",
    "            else:\n",
    "                # If confidence intervals are not available, plot a placeholder\n",
    "                ci = pd.DataFrame(index=forecasted_data.index, data=np.nan, columns=['lower', 'upper'])\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.tight_layout()\n",
    "            plt.grid()\n",
    "            plt.title(f'Store {store_k}, Item {item_k} Forecast')\n",
    "            plt.xlabel('Date')\n",
    "            plt.ylabel('Unit Sales')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "        # Calculate Bias, MAD, rMAD\n",
    "        forecasted_data['Bias'] = forecasted_data['unit_sales'] - forecasted_data['forcasted_unit_sales']\n",
    "        Bias = forecasted_data['Bias'].mean()\n",
    "        MAD = forecasted_data['Bias'].abs().mean()\n",
    "        rMAD = forecasted_data['Bias'].abs().mean() / forecasted_data['unit_sales'].mean()\n",
    "\n",
    "        # calculate the r2 and mae\n",
    "        r2 = r2_score(forecasted_data['unit_sales'], forecasted_data['forcasted_unit_sales'])\n",
    "        mae = mean_absolute_error(forecasted_data['unit_sales'], forecasted_data['forcasted_unit_sales'])\n",
    "\n",
    "\n",
    "        # Store the Bias, MAD, rMAD in the dictionary\n",
    "        stores_forecasts[store_k][item_k]['Bias'] = Bias.round(2)\n",
    "        stores_forecasts[store_k][item_k]['MAD'] = MAD.round(2)\n",
    "        stores_forecasts[store_k][item_k]['rMAD'] = rMAD.round(2)\n",
    "        stores_forecasts[store_k][item_k]['r2'] = round(r2,2)\n",
    "        stores_forecasts[store_k][item_k]['mae'] = round(mae,2)\n",
    "\n",
    "# Model Evaluation\n",
    "        # Print the Bias, MAD, rMAD\n",
    "        print(f'{count}. Store {store_k}, Item {item_k} Bias: {Bias.round(2)}, MAD: {MAD.round(2)}, rMAD: {rMAD.round(2)}, r2: {round(r2,2)}, mae: {round(mae,2)}')\n",
    "\n",
    "        #break\n",
    "    #break\n",
    "    print('-'*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G-go-1llLCBH"
   },
   "outputs": [],
   "source": [
    "def convert_types(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: convert_types(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_types(i) for i in obj]\n",
    "    elif isinstance(obj, (np.integer, np.int64)):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, (np.floating, np.float64)):\n",
    "        return float(obj)\n",
    "    else:\n",
    "        return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PYNyjygCLCBH",
    "outputId": "379acf37-3453-4d89-8269-3ca40612a582"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stores forecasts saved to /Users/D065623/Documents/Amna/Time_series_project/Forcasting_app/forecasts/stores_forecasts_15.json\n"
     ]
    }
   ],
   "source": [
    "# save the stores_forecasts dictionary to a json file\n",
    "json_save_path = '/Users/D065623/Documents/Amna/Time_series_project/Forcasting_app/forecasts/stores_forecasts_15.json'\n",
    "with open(json_save_path, 'w') as f:\n",
    "    json.dump(convert_types(stores_forecasts), f)\n",
    "print(f'Stores forecasts saved to {json_save_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2o2IGx_bLCBI"
   },
   "source": [
    "### 3.3- Load json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wZU5zl-xLCBI"
   },
   "outputs": [],
   "source": [
    "# load the stores_forecasts dictionary from the json file\n",
    "json_save_path = '/Users/D065623/Documents/Amna/Time_series_project/Forcasting_app/forecasts/stores_forecasts_15.json'\n",
    "with open(json_save_path, 'r') as f:\n",
    "     stores_forecasts = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-m90Ivp3LCBI"
   },
   "outputs": [],
   "source": [
    "# create a key 'date' in the stores_forecasts dictionary. and populate it with two further keys 'train_data_dates' and 'test_data_dates'. Then save the unique dates from the df dataframe to 'train_data_dates' and 'test_data_dates'\n",
    "stores_forecasts['date'] = {}\n",
    "unique_dates = df['date'].unique()\n",
    "\n",
    "# select unique dates from unique_dates list till '2013-12-31' in a new list\n",
    "unique_dates_df = pd.DataFrame(unique_dates, columns=['date'])\n",
    "train_data_dates = unique_dates_df[unique_dates_df['date'] < '2014-01-01']\n",
    "test_data_dates = unique_dates_df[unique_dates_df['date'] >= '2014-01-01']\n",
    "\n",
    "# limit the test_data_dates to 15 days\n",
    "test_data_dates = test_data_dates.head(n_periods)\n",
    "\n",
    "stores_forecasts['date']['train_data_dates'] = train_data_dates['date'].tolist()\n",
    "stores_forecasts['date']['test_data_dates'] = test_data_dates['date'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YvvutK_tLCBI",
    "outputId": "34ff3266-b8af-4166-9f1c-8fd8dfd58b39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stores forecasts saved to /Users/D065623/Documents/Amna/Time_series_project/Forcasting_app/forecasts/stores_forecasts_15.json\n"
     ]
    }
   ],
   "source": [
    "# update the stores_forecast dictionary to json file 'stores_forecasts_3.json'\n",
    "json_save_path = '/Users/D065623/Documents/Amna/Time_series_project/Forcasting_app/forecasts/stores_forecasts_15.json'\n",
    "with open(json_save_path, 'w') as f:\n",
    "    json.dump(convert_types(stores_forecasts), f)\n",
    "print(f'Stores forecasts saved to {json_save_path}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1tN2Kyfeu2F7lR4TaGonYr5ArF2PsFClF",
     "timestamp": 1749594040041
    },
    {
     "file_id": "1MXnDRU-MgW0ByXOFrBJJwRgar7H5fIlv",
     "timestamp": 1749558151705
    },
    {
     "file_id": "1zmx1xnXN0AwzyCXJQvj894SHPCurtjvC",
     "timestamp": 1745567234209
    },
    {
     "file_id": "14pUQ4V4trKhm5MUSJJu05Dw7gQD49Jf1",
     "timestamp": 1744318008178
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
